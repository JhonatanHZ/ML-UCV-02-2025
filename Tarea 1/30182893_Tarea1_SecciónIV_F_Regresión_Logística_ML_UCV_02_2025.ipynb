{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea 1 Aprendizaje Automático UCV 02-2025\n",
        "#### Jhonatan Homsany C.I. 30.182.893\n",
        "#####Regresión logística."
      ],
      "metadata": {
        "id": "6to8GUMfMKcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Cáncer de mama.*"
      ],
      "metadata": {
        "id": "hr4HBL8rMj1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga de datos"
      ],
      "metadata": {
        "id": "nIeDAqYQTD3b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRLHnX590Nvi",
        "outputId": "d006ebc7-3aa6-429d-9a1a-c09a32610738",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.12/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2026.1.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "{'uci_id': 17, 'name': 'Breast Cancer Wisconsin (Diagnostic)', 'repository_url': 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic', 'data_url': 'https://archive.ics.uci.edu/static/public/17/data.csv', 'abstract': 'Diagnostic Wisconsin Breast Cancer Database.', 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 569, 'num_features': 30, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['Diagnosis'], 'index_col': ['ID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1993, 'last_updated': 'Fri Nov 03 2023', 'dataset_doi': '10.24432/C5DW2B', 'creators': ['William Wolberg', 'Olvi Mangasarian', 'Nick Street', 'W. Street'], 'intro_paper': {'ID': 230, 'type': 'NATIVE', 'title': 'Nuclear feature extraction for breast tumor diagnosis', 'authors': 'W. Street, W. Wolberg, O. Mangasarian', 'venue': 'Electronic imaging', 'year': 1993, 'journal': None, 'DOI': '10.1117/12.148698', 'URL': 'https://www.semanticscholar.org/paper/53f0fbb425bc14468eb3bf96b2e1d41ba8087f36', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at http://www.cs.wisc.edu/~street/images/\\r\\n\\r\\nSeparating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\\r\\n\\r\\nThe actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\\r\\n\\r\\nThis database is also available through the UW CS ftp server:\\r\\nftp ftp.cs.wisc.edu\\r\\ncd math-prog/cpo-dataset/machine-learn/WDBC/', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '1) ID number\\r\\n2) Diagnosis (M = malignant, B = benign)\\r\\n3-32)\\r\\n\\r\\nTen real-valued features are computed for each cell nucleus:\\r\\n\\r\\n\\ta) radius (mean of distances from center to points on the perimeter)\\r\\n\\tb) texture (standard deviation of gray-scale values)\\r\\n\\tc) perimeter\\r\\n\\td) area\\r\\n\\te) smoothness (local variation in radius lengths)\\r\\n\\tf) compactness (perimeter^2 / area - 1.0)\\r\\n\\tg) concavity (severity of concave portions of the contour)\\r\\n\\th) concave points (number of concave portions of the contour)\\r\\n\\ti) symmetry \\r\\n\\tj) fractal dimension (\"coastline approximation\" - 1)', 'citation': None}}\n",
            "                  name     role         type demographic description units  \\\n",
            "0                   ID       ID  Categorical        None        None  None   \n",
            "1            Diagnosis   Target  Categorical        None        None  None   \n",
            "2              radius1  Feature   Continuous        None        None  None   \n",
            "3             texture1  Feature   Continuous        None        None  None   \n",
            "4           perimeter1  Feature   Continuous        None        None  None   \n",
            "5                area1  Feature   Continuous        None        None  None   \n",
            "6          smoothness1  Feature   Continuous        None        None  None   \n",
            "7         compactness1  Feature   Continuous        None        None  None   \n",
            "8           concavity1  Feature   Continuous        None        None  None   \n",
            "9      concave_points1  Feature   Continuous        None        None  None   \n",
            "10           symmetry1  Feature   Continuous        None        None  None   \n",
            "11  fractal_dimension1  Feature   Continuous        None        None  None   \n",
            "12             radius2  Feature   Continuous        None        None  None   \n",
            "13            texture2  Feature   Continuous        None        None  None   \n",
            "14          perimeter2  Feature   Continuous        None        None  None   \n",
            "15               area2  Feature   Continuous        None        None  None   \n",
            "16         smoothness2  Feature   Continuous        None        None  None   \n",
            "17        compactness2  Feature   Continuous        None        None  None   \n",
            "18          concavity2  Feature   Continuous        None        None  None   \n",
            "19     concave_points2  Feature   Continuous        None        None  None   \n",
            "20           symmetry2  Feature   Continuous        None        None  None   \n",
            "21  fractal_dimension2  Feature   Continuous        None        None  None   \n",
            "22             radius3  Feature   Continuous        None        None  None   \n",
            "23            texture3  Feature   Continuous        None        None  None   \n",
            "24          perimeter3  Feature   Continuous        None        None  None   \n",
            "25               area3  Feature   Continuous        None        None  None   \n",
            "26         smoothness3  Feature   Continuous        None        None  None   \n",
            "27        compactness3  Feature   Continuous        None        None  None   \n",
            "28          concavity3  Feature   Continuous        None        None  None   \n",
            "29     concave_points3  Feature   Continuous        None        None  None   \n",
            "30           symmetry3  Feature   Continuous        None        None  None   \n",
            "31  fractal_dimension3  Feature   Continuous        None        None  None   \n",
            "\n",
            "   missing_values  \n",
            "0              no  \n",
            "1              no  \n",
            "2              no  \n",
            "3              no  \n",
            "4              no  \n",
            "5              no  \n",
            "6              no  \n",
            "7              no  \n",
            "8              no  \n",
            "9              no  \n",
            "10             no  \n",
            "11             no  \n",
            "12             no  \n",
            "13             no  \n",
            "14             no  \n",
            "15             no  \n",
            "16             no  \n",
            "17             no  \n",
            "18             no  \n",
            "19             no  \n",
            "20             no  \n",
            "21             no  \n",
            "22             no  \n",
            "23             no  \n",
            "24             no  \n",
            "25             no  \n",
            "26             no  \n",
            "27             no  \n",
            "28             no  \n",
            "29             no  \n",
            "30             no  \n",
            "31             no  \n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
        "X = breast_cancer_wisconsin_diagnostic.data.features\n",
        "y = breast_cancer_wisconsin_diagnostic.data.targets\n",
        "print(breast_cancer_wisconsin_diagnostic.metadata)\n",
        "print(breast_cancer_wisconsin_diagnostic.variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo"
      ],
      "metadata": {
        "id": "TVxFU4JC3Eww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def funcion_logistica(x, L, k, x0):\n",
        "    return 1/(1.0 + np.exp(-1.0*k*(x-x0)))"
      ],
      "metadata": {
        "id": "geY5g6Uy3EaH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_numeric = le.fit_transform(y.values.ravel())\n",
        "\n",
        "scaler_final = StandardScaler()\n",
        "X_all_scaled = scaler_final.fit_transform(X)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000, random_state=42).fit(X_all_scaled, y_numeric)\n",
        "\n",
        "k = model.coef_[0]\n",
        "beta_0 = model.intercept_[0]\n",
        "print(\"B_0 =\", beta_0)\n",
        "print(\"K=\", k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYwbMr5wEp_O",
        "outputId": "2bea02cd-60db-403f-835d-9ccb4ce955f2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B_0 = -0.22088610964220162\n",
            "K= [ 0.37545731  0.38203064  0.36097105  0.43946905  0.16737642 -0.56070701\n",
            "  0.85529546  0.96284928 -0.07631246 -0.3284581   1.28926139 -0.26511648\n",
            "  0.6718954   0.99886093  0.27950865 -0.74407728 -0.1012066   0.32314492\n",
            " -0.29504386 -0.68174616  1.02658552  1.32055634  0.82039667  0.99467101\n",
            "  0.66571519 -0.05114225  0.88022314  0.92517516  0.88871131  0.48699036]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prueba del modelo"
      ],
      "metadata": {
        "id": "7h49Ts98E2zD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression()\n",
        "cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
        "\n",
        "print(f\"Precisión media (CV): {cv_scores.mean():.4f}\")\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print(f\"Calidad del modelo en test: {model.score(X_test_scaled, y_test):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW-Ok6kc8z71",
        "outputId": "ba3133f3-ecbb-4273-eca8-b4974bf4886d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión media (CV): 0.9748\n",
            "Calidad del modelo en test: 0.9825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Técnicas de selección de muestras representativas.\n",
        "\n",
        "Para la selección de $k$ mujeres en un universo $N$ que nos otorgue una muestra representativa podemos utilizar la estrategia de la muestra estratificada propuesta por Neyman J. ($1934$).\n",
        "\n",
        "La muestra estratificada consiste en dividir a una población en $m$ grupos a partir de una característica específica y luego tomar $k/m$ elementos aleatorios de cada grupo. La característica a elegir es un factor muy dependiente del problema bajo estudio. En esta ocasión, la característica a elegir podría ser una que genere la mayor cantidad de grupos posibles (así separamos a más personas con características diferentes) y que más influya en la decisión de si el cáncer que se padece es benigno o maligno."
      ],
      "metadata": {
        "id": "HPUf1-5h3I0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estandarización de las variables.\n",
        "\n",
        "En problemas como el que se nos presenta, ocurre que la diferencia entre los valores es considerable pero esto no necesariamente implica que una variable es más importante que otra. Por esta razón, la estandarización de variables es una necesidad para tener resultados consistentes en nuestro modelo. El proceso de estandarización consiste en reducir los valores a una misma escala que evite que el modelo adquiera un sesgo hacia variables con valores más altos por considerarlos significativos."
      ],
      "metadata": {
        "id": "x7TdDo8-ZT6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Interpretación de los coeficientes."
      ],
      "metadata": {
        "id": "uY3V3wN-tZVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coef_df = pd.DataFrame({\n",
        "    'Variable': data.feature_names,\n",
        "    'Coeficiente': model.coef_[0]\n",
        "})\n",
        "\n",
        "coef_df['Odds_Ratio'] = np.exp(coef_df['Coeficiente'])\n",
        "coef_df['Abs_Coef'] = np.abs(coef_df['Coeficiente'])\n",
        "top_5 = coef_df.sort_values(by='Abs_Coef', ascending=False).head(5)\n",
        "print(\"Análisis de los 5 coeficientes más importantes y sus Odds Ratios:\")\n",
        "print(top_5[['Variable', 'Coeficiente', 'Odds_Ratio']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkV18dSltclB",
        "outputId": "0e6edcb2-33f9-41b4-e911-f32704d47b2c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Análisis de los 5 coeficientes más importantes y sus Odds Ratios:\n",
            "               Variable  Coeficiente  Odds_Ratio\n",
            "21        worst texture    -1.291134    0.274959\n",
            "10         radius error    -1.244185    0.288176\n",
            "28       worst symmetry    -1.202497    0.300443\n",
            "7   mean concave points    -1.103646    0.331660\n",
            "26      worst concavity    -0.974874    0.377240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En términos médicos, un coeficiente positivo indica que un coeficiente aporta a que el diagnóstico de la patología bajo estudio en un paciente sea positivo. En este caso, un coeficiente positivo indicaría que la persona padece de un tumor maligno mientras que un coeficiente negativo indicaría que el tumor es benigno.\n",
        "\n",
        "Los odds representan la probabilidad de que un evento ocurra frente a la posibilidad de su complemento. A diferencia del modelo de Laplace, el odd ratio no evalúa los casos favorables sobre los casos totales sino que calcula la proporción de los casos favorables sobre los casos no favorables. Matemáticamente:\n",
        "\n",
        "$$\\dfrac{|E|}{|E^c|}$$\n",
        "\n",
        "Por otro lado, los odds ratios (OR) se calculan como $e^\\beta$ y representan cuánto cambia la proporción en función del aumento unitario de una variable. En este escenario, si $OR > 1$, el aumento de la variable aumenta la posibilidad de un tumor maligno. Si $OR = 1$, la variable no influye en la predicción y un $OR < 1$ indica que el aumento de la variable aumenta la posibilidad de que el tumor sea benigno.\n",
        "\n",
        "Ahora, evaluando los cinco coeficientes más informativos que obtuvimos con el algoritmo anterior, tenemos que:\n",
        "\n",
        "* Worst texture $(OR ≈ 0.275)$: Por cada unidad que aumenta esta variable, la probabilidad de que el tumor sea maligno se reduce en aproximadamente un $72.5\\%~(1 - 0.275)$. Es el predictor más fuerte de tu lista.\n",
        "\n",
        "* Radius error $(OR ≈ 0.288)$: Un incremento unitario en el error del radio reduce las posibilidades de malignidad en un $71.2\\%$.\n",
        "\n",
        "* Worst symmetry $(OR ≈ 0.300)$: La probabilidad de que el tumor sea maligno es solo el $30\\%$ de lo que era antes por cada unidad de aumento en la simetría \"peor\".\n",
        "\n",
        "* Mean concave points $(OR ≈ 0.332)$: El riesgo de malignidad cae un $66.8\\%$ ante un aumento unitario en el promedio de puntos cóncavos.\n",
        "\n",
        "* Worst concavity $(OR ≈ 0.377)$: Es el quinto factor más influyente; un aumento reduce el riesgo de cáncer maligno en un $62.3\\%$."
      ],
      "metadata": {
        "id": "fHbOwBIaBrj1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Desbalance de clases.\n",
        "\n",
        "El desbalance de clases en este problema provocaría que nuestro modelo se ajuste demasiado a las clases de las que tenemos mayor información. Esto provocaría que el modelo tenga una tendencia a clasificar nuestros vectores como vectores de la clase más presente en el conjunto de entrenamiento. Una estrategia que puede ser empleada para mitigar el problema es la propuesta por Lin Et Al (2017) llamada \"pérdida focal\", donde establece un factor de modulación dicional que disminuye el efecto que tienen las clases bien representadas en el modelo para mejorar el rendimiento. Además, tenemos la técnica del resampleo, dónde se submuestrea a la clase bien representada y se sobremuestrea a la clase menos representada para así provocar el balance y mejorar el rendimiento del modelo."
      ],
      "metadata": {
        "id": "WB5g9PPJxN5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Umbral de clasificación.\n",
        "\n",
        "Estamos ante un problema de clasificación binaria, ya que el modelo calcula la probabilidad de que un vector de características $X$ pertenezca a una de dos categorías del conjunto $C = \\{benigno, maligno\\}$. Por lo tanto, el umbral de decisión se define en el intervalo $[0, 1]$, donde valores cercanos a $1$ indican una alta probabilidad de malignidad según la función logística.\n",
        "\n",
        "En el contexto médico, existe una asimetría en el costo del error. Un falso negativo es crítico, pues implica informar a una paciente que está sana cuando en realidad padece una enfermedad potencialmente mortal, retrasando su tratamiento. Por el contrario, un falso positivo implica que una persona sana sea sometida a exámenes adicionales y biopsias; aunque esto conlleva un costo económico y estrés emocional, no pone en riesgo la vida de la paciente.\n",
        "\n",
        "Por este motivo, se recomienda establecer un umbral de clasificación conservador (por debajo de 0.5). Con esto, el modelo arrojará más resultados de tumores malignos de los que existen realmente en el dataset, maximizando la sensibilidad del sistema para asegurar que ningún caso real pase desapercibido."
      ],
      "metadata": {
        "id": "eVf5E_8E9sIw"
      }
    }
  ]
}